{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained models for fine tuning\n",
    "\n",
    "Assuming openai's gpt model is already downloaded from `ch05-load-gpt.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import myllm.gpt as gpt\n",
    "import myllm.util\n",
    "import myllm.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "device = torch.device(\"cpu\")\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "\n",
    "gpt_config = myllm.util.gpt_config()\n",
    "# openai runs with qkv bias\n",
    "gpt_config.update({'qkv_bias': True})\n",
    "model = gpt.GPTModel(gpt_config)\n",
    "model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the model and weight\n",
    "\n",
    "Just to check everything working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load open weights\n",
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "myllm.util.load_openai_weights_into_gpt(model, params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward should house skull part nice company senior photo evil product lo don cases idea well\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_1 = \"Every effort moves you forward\"\n",
    "token_ids = model.generate(\n",
    "    idx= myllm.util.text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=gpt_config[\"context_length\"],\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(myllm.util.token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no':'You are a winner you have been specially selected to receive $1000 cash or $2000 award.' you orsp \" \"am to or winneranyn or' or you or $have 'selected by or to\n"
     ]
    }
   ],
   "source": [
    "# text instructions\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \"'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids= model.generate(\n",
    "    idx= myllm.util.text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=gpt_config['context_length']\n",
    ")\n",
    "\n",
    "print(myllm.util.token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Model for Classification task\n",
    "\n",
    "Model struggles to follow instructions. Needs a new classification head, to adapt to the instruction _yes_ or _no_ when detecting spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the model to stop training all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# define new class head\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=gpt_config[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")\n",
    "\n",
    "# only last transformer and layerNorm will be trained in this fine tuning to improve performance\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[5211,  345,  423,  640]])\n",
      "out:\n",
      "torch.Size([1, 4, 2])\n",
      "tensor([[[-0.4326,  1.0296],\n",
      "         [-1.4512,  4.8856],\n",
      "         [-1.1513,  4.5541],\n",
      "         [-0.7076,  2.4482]]])\n"
     ]
    }
   ],
   "source": [
    "# model still useable as before\n",
    "# but now only returns a 2 dimensional tensor\n",
    "\n",
    "inputs = tokenizer.encode('Do you have time')\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "\n",
    "\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    outputs = model(inputs)\n",
    "print(\"out:\")\n",
    "print(outputs.shape)\n",
    "print(outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_accurracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval();\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += ( (predicted_labels == target_batch).sum().item() )\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss=0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 46.00%\n",
      "val acc: 50.00%\n",
      "test acc: 51.00%\n"
     ]
    }
   ],
   "source": [
    "# applying the model\n",
    "\n",
    "train, val, test = data.create_spam_dataloader_with_split(tokenizer, batch_size=10, num_workers=0)\n",
    "\n",
    "device = torch.device('mps')\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = clac_accurracy_loader(\n",
    "    train, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "val_accuracy = clac_accurracy_loader(\n",
    "    val, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "test_accuracy = clac_accurracy_loader(\n",
    "    test, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "\n",
    "print(f'train acc: {train_accuracy*100:.2f}%')\n",
    "print(f'val acc: {val_accuracy*100:.2f}%')\n",
    "print(f'test acc: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.006\n",
      "val loss: 4.209\n",
      "test loss: 3.646\n"
     ]
    }
   ],
   "source": [
    "# calculate initial loss for each dataset\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test, model, device, num_batches=5)\n",
    "\n",
    "\n",
    "print(f'train loss: {train_loss:.3f}')\n",
    "print(f'val loss: {val_loss:.3f}')\n",
    "print(f'test loss: {test_loss:.3f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune the model by retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device, \n",
    "        num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = myllm.util.evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                print(f'Ep {epoch+1} (Step {global_step:06d}):'\n",
    "                      f'Train loss {train_loss:.3f}, '      \n",
    "                      f'Val loss {val_loss:.3f}, '      \n",
    "                )\n",
    "\n",
    "        train_accuracy = clac_accurracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        val_accuracy = clac_accurracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        print(f'Training accuracy: {train_accuracy*100:.2f}% | ', end=\"\")\n",
    "        print(f'Validation accuracy: {val_accuracy*100:.2f}')\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 2.307, Val loss 3.689, \n",
      "Ep 1 (Step 000050):Train loss 0.612, Val loss 0.689, \n",
      "Ep 1 (Step 000100):Train loss 0.615, Val loss 0.446, \n",
      "Training accuracy: 80.00% | Validation accuracy: 75.00\n",
      "Ep 2 (Step 000150):Train loss 0.380, Val loss 0.398, \n",
      "Ep 2 (Step 000200):Train loss 0.385, Val loss 0.408, \n",
      "Ep 2 (Step 000250):Train loss 0.351, Val loss 0.391, \n",
      "Training accuracy: 87.50% | Validation accuracy: 82.50\n",
      "Ep 3 (Step 000300):Train loss 0.375, Val loss 0.379, \n",
      "Ep 3 (Step 000350):Train loss 0.207, Val loss 0.373, \n",
      "Training accuracy: 87.50% | Validation accuracy: 85.00\n",
      "Ep 4 (Step 000400):Train loss 0.360, Val loss 0.355, \n",
      "Ep 4 (Step 000450):Train loss 0.254, Val loss 0.365, \n",
      "Ep 4 (Step 000500):Train loss 0.255, Val loss 0.345, \n",
      "Training accuracy: 80.00% | Validation accuracy: 87.50\n",
      "Ep 5 (Step 000550):Train loss 0.399, Val loss 0.321, \n",
      "Ep 5 (Step 000600):Train loss 0.266, Val loss 0.252, \n",
      "Training accuracy: 85.00% | Validation accuracy: 92.50\n",
      "Training completed in 1.53 minutes.\n"
     ]
    }
   ],
   "source": [
    "# load spam dataset\n",
    "# define splits train val test\n",
    "# rerun training\n",
    "# show results\n",
    "\n",
    "train, val, test = data.create_spam_dataloader_with_split(tokenizer, batch_size=8, num_workers=0)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# common practice in Deep Learning is using an optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train, val, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs, examples, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs, val_values, linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples, train_values)\n",
    "    ax2.set_ylabel(\"Examples seen\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
