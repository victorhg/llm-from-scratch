
Can I create a Large Language Model from scratch?

- Source of study [Build a Large Language Model - Sebastian Raschka](https://www.amazon.com/Build-Large-Language-Model-Scratch/dp/1633437167)

- Video Reference: [Build an LLM from scratch](https://www.youtube.com/watch?v=kPGTx4wcm_w)


## What to Learn Here so far

My journey learning how Transformers working to build a Large Language Model. Describing the process backwards

- Using an text entry, define a tokenization process that will be used for training
- Generate Embedding representations of tokens
- Recreate the multiple layers of the Transformer Architecture
- Create the Attention Mechanism that is the most important aspect of the LLM 'revolution'
- Train a neural network model using the Transformer Architecture 
- Load a Model and execute the Text Generation Process using the class `GPTModel` 
- Use the GPT2 open weights to load the models in our own architecture




